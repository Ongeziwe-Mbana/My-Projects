{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we prepared the stock data. Now we will use it to build a regression model to predict stock returns. We will look at our first algorithm - Multifactor Linear Regression (MLR) - where we will simultaneously take you through the model building process in python using Scikit Learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Multifactor Linear Regression Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **multifactor linear model** has the form:\n",
    "\n",
    "$$Y~=~\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p+error$$\n",
    "\n",
    "where $X_i$ is the i'th feature (predictor) and $\\beta_i$ is the coefficient of the i'th feature.\n",
    "\n",
    "We fit a model to predict $Y$ by estimating values for all the coefficients. \n",
    "\n",
    "The coefficients are estimated by minimizing the **least squares**:\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Multifactor Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Scikit Learn to build our multifactor linear model to predict stock returns. Building a model in Scikit Learn consist of the following steps: \n",
    "* Preprocessing of the data\n",
    "* Training/fitting the model\n",
    "* Predicting results\n",
    "* Testing the output\n",
    "\n",
    "We will go through each of the steps above. Let's start by importing the libraries we will need and read in the data.csv file we created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>company</th>\n",
       "      <th>current_price</th>\n",
       "      <th>momentum</th>\n",
       "      <th>moving_average</th>\n",
       "      <th>moving_volatility</th>\n",
       "      <th>trading_range</th>\n",
       "      <th>target_return</th>\n",
       "      <th>exp_market_change</th>\n",
       "      <th>rates</th>\n",
       "      <th>...</th>\n",
       "      <th>Gross_profit</th>\n",
       "      <th>Operating_profit</th>\n",
       "      <th>Net_Profit</th>\n",
       "      <th>Issue_of_shares</th>\n",
       "      <th>Share_repurchase</th>\n",
       "      <th>Non_current_assets</th>\n",
       "      <th>Current_assets</th>\n",
       "      <th>Non_current_liabilities</th>\n",
       "      <th>Current_liabilities</th>\n",
       "      <th>net_cash_op_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/02/17</td>\n",
       "      <td>Anglogold Ashanti Ltd</td>\n",
       "      <td>29500.0</td>\n",
       "      <td>-0.103343</td>\n",
       "      <td>30598.216667</td>\n",
       "      <td>1854.530002</td>\n",
       "      <td>850.550000</td>\n",
       "      <td>0.090136</td>\n",
       "      <td>-0.016852</td>\n",
       "      <td>7.08</td>\n",
       "      <td>...</td>\n",
       "      <td>329.5</td>\n",
       "      <td>431.7</td>\n",
       "      <td>317.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>732.8</td>\n",
       "      <td>237.2</td>\n",
       "      <td>220.7</td>\n",
       "      <td>454.3</td>\n",
       "      <td>959.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/05/06</td>\n",
       "      <td>Anglogold Ashanti Ltd</td>\n",
       "      <td>31150.0</td>\n",
       "      <td>0.139982</td>\n",
       "      <td>28743.150000</td>\n",
       "      <td>1079.933674</td>\n",
       "      <td>697.066667</td>\n",
       "      <td>-0.053612</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>6.58</td>\n",
       "      <td>...</td>\n",
       "      <td>239.3</td>\n",
       "      <td>141.3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>741.4</td>\n",
       "      <td>188.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>396.3</td>\n",
       "      <td>816.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/08/11</td>\n",
       "      <td>Anglogold Ashanti Ltd</td>\n",
       "      <td>31420.0</td>\n",
       "      <td>-0.026943</td>\n",
       "      <td>31682.016667</td>\n",
       "      <td>1388.464601</td>\n",
       "      <td>864.983333</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>6.42</td>\n",
       "      <td>...</td>\n",
       "      <td>381.9</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>719.6</td>\n",
       "      <td>203.3</td>\n",
       "      <td>306.8</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/11/10</td>\n",
       "      <td>Anglogold Ashanti Ltd</td>\n",
       "      <td>34987.0</td>\n",
       "      <td>0.096771</td>\n",
       "      <td>32142.716667</td>\n",
       "      <td>784.923382</td>\n",
       "      <td>705.033333</td>\n",
       "      <td>-0.060365</td>\n",
       "      <td>0.136024</td>\n",
       "      <td>5.65</td>\n",
       "      <td>...</td>\n",
       "      <td>400.9</td>\n",
       "      <td>138.2</td>\n",
       "      <td>44.3</td>\n",
       "      <td>559.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>248.5</td>\n",
       "      <td>412.7</td>\n",
       "      <td>197.5</td>\n",
       "      <td>1056.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011/02/16</td>\n",
       "      <td>Anglogold Ashanti Ltd</td>\n",
       "      <td>33230.0</td>\n",
       "      <td>-0.007586</td>\n",
       "      <td>32411.016667</td>\n",
       "      <td>1134.366223</td>\n",
       "      <td>629.016667</td>\n",
       "      <td>-0.061601</td>\n",
       "      <td>0.076571</td>\n",
       "      <td>5.53</td>\n",
       "      <td>...</td>\n",
       "      <td>407.9</td>\n",
       "      <td>197.8</td>\n",
       "      <td>40.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>779.3</td>\n",
       "      <td>172.3</td>\n",
       "      <td>444.2</td>\n",
       "      <td>97.4</td>\n",
       "      <td>1095.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                 company  current_price  momentum  \\\n",
       "0  2010/02/17   Anglogold Ashanti Ltd        29500.0 -0.103343   \n",
       "1  2010/05/06   Anglogold Ashanti Ltd        31150.0  0.139982   \n",
       "2  2010/08/11   Anglogold Ashanti Ltd        31420.0 -0.026943   \n",
       "3  2010/11/10   Anglogold Ashanti Ltd        34987.0  0.096771   \n",
       "4  2011/02/16   Anglogold Ashanti Ltd        33230.0 -0.007586   \n",
       "\n",
       "   moving_average  moving_volatility  trading_range  target_return  \\\n",
       "0    30598.216667        1854.530002     850.550000       0.090136   \n",
       "1    28743.150000        1079.933674     697.066667      -0.053612   \n",
       "2    31682.016667        1388.464601     864.983333       0.050286   \n",
       "3    32142.716667         784.923382     705.033333      -0.060365   \n",
       "4    32411.016667        1134.366223     629.016667      -0.061601   \n",
       "\n",
       "   exp_market_change  rates       ...         Gross_profit  Operating_profit  \\\n",
       "0          -0.016852   7.08       ...                329.5             431.7   \n",
       "1           0.044321   6.58       ...                239.3             141.3   \n",
       "2           0.008204   6.42       ...                381.9              -8.9   \n",
       "3           0.136024   5.65       ...                400.9             138.2   \n",
       "4           0.076571   5.53       ...                407.9             197.8   \n",
       "\n",
       "   Net_Profit  Issue_of_shares  Share_repurchase  Non_current_assets  \\\n",
       "0       317.9              3.9               3.9               732.8   \n",
       "1       115.0              0.3               0.0               741.4   \n",
       "2      -136.0              2.6               0.0               719.6   \n",
       "3        44.3            559.6               0.0               753.0   \n",
       "4        40.4              3.1               3.1               779.3   \n",
       "\n",
       "   Current_assets  Non_current_liabilities  Current_liabilities  \\\n",
       "0           237.2                    220.7                454.3   \n",
       "1           188.0                    221.0                396.3   \n",
       "2           203.3                    306.8                328.0   \n",
       "3           248.5                    412.7                197.5   \n",
       "4           172.3                    444.2                 97.4   \n",
       "\n",
       "   net_cash_op_act  \n",
       "0            959.6  \n",
       "1            816.6  \n",
       "2           1003.0  \n",
       "3           1056.6  \n",
       "4           1095.5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing in sklearn involves:\n",
    "* Manipulating the data\n",
    "* Splitting the data into features and labels\n",
    "* Transforming the data \n",
    "* Splitting the data into training and testing data.\n",
    "\n",
    "We already did most of our heavy lifting in the previous tutorial, however there is still some work left.\n",
    "\n",
    "Transforming the features (e.g. Normalizing/standardizing) is not always required for multifactor linear regression (although we will do so in the next tutorial, when we consider regularization techiniques to improve our model). So we will only split the data into features and labels and then into training and testing data. \n",
    "\n",
    "#### Features/Labels split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features relate to the independent variables or predictors while labels relate to the dependent variable or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lables\n",
    "y = df['target_return']\n",
    "\n",
    "# Features\n",
    "X = df.drop(['Date', 'company', 'target_return'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the shape method to see the number of rows and columns (features) in our features data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to split our data into training and testing data. We do this to fit our model using the training data while we test the output of our model on the testing (unseen) data. Ideally we want a model that has a good fit to both the training and the testing data, however this is rarely the case. The fit to the training data gives us an idea of the bias in the model while the fit to the testing data gives us an idea of the variance in the model.\n",
    "\n",
    "**Bias** relates to the degree to which our model is an accurate representation of reality: for example, if the relationships between variables are very non-linear and we're using a linear model (such as multiple linear regression), then our model will have high bias. **Variance**, on the other hand, relates to how well our model generalizes to unseen data: a model with high variance will be very sensitive to changes in the training data set. A large part of the modelling challenge lies in understanding and optimising the so-called **bias-variance tradeoff**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the train_test_split method from sklearn.model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the imported method to split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the data split we can use the training data to train the model - i.e. learn the optimal parameters used to predict future results.\n",
    "\n",
    "We import LinearRegression from sklearn.linear_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the LinearRegression object so that we can use methods on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the fit() method to train the model. Note that we only input the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can extract the parameters. The parameters consist of the intercept and the coefficients related to the features. These parameters can be used to predict future share returns given the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23577102387826848"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **intercept** above can be interpreted as the expected stock return if all of the feature values are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>current_price</th>\n",
       "      <td>6.365389e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum</th>\n",
       "      <td>-2.155042e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving_average</th>\n",
       "      <td>-5.965514e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving_volatility</th>\n",
       "      <td>1.007698e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trading_range</th>\n",
       "      <td>-1.968718e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_market_change</th>\n",
       "      <td>-3.367112e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates</th>\n",
       "      <td>-3.398462e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue</th>\n",
       "      <td>-1.736386e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cost_of_Sales</th>\n",
       "      <td>1.726277e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gross_profit</th>\n",
       "      <td>1.727082e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operating_profit</th>\n",
       "      <td>-2.677717e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net_Profit</th>\n",
       "      <td>-1.644971e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Issue_of_shares</th>\n",
       "      <td>6.772340e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Share_repurchase</th>\n",
       "      <td>5.879247e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non_current_assets</th>\n",
       "      <td>-2.912547e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current_assets</th>\n",
       "      <td>6.251771e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non_current_liabilities</th>\n",
       "      <td>2.428064e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current_liabilities</th>\n",
       "      <td>3.047814e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_cash_op_act</th>\n",
       "      <td>8.058685e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Coefficient\n",
       "current_price            6.365389e-07\n",
       "momentum                -2.155042e-02\n",
       "moving_average          -5.965514e-07\n",
       "moving_volatility        1.007698e-05\n",
       "trading_range           -1.968718e-05\n",
       "exp_market_change       -3.367112e-01\n",
       "rates                   -3.398462e-02\n",
       "Revenue                 -1.736386e-05\n",
       "Cost_of_Sales            1.726277e-05\n",
       "Gross_profit             1.727082e-05\n",
       "Operating_profit        -2.677717e-07\n",
       "Net_Profit              -1.644971e-06\n",
       "Issue_of_shares          6.772340e-08\n",
       "Share_repurchase         5.879247e-07\n",
       "Non_current_assets      -2.912547e-09\n",
       "Current_assets           6.251771e-09\n",
       "Non_current_liabilities  2.428064e-08\n",
       "Current_liabilities      3.047814e-09\n",
       "net_cash_op_act          8.058685e-07"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **coefficient** can be interpreted as the expected change in the stock return if the feature value increases by 1. For example the stock return is expected to increase by 0.095 if the momentum increased by 1 (i.e. -0.1 => 0.9).\n",
    "\n",
    "The **sign of the coefficients** also gives us an indication of which way an increase or decrease in feature value affects our expected stock return. For example because the sign of revenue is positive it implies that we expect higher returns given higher revenue in the past quarter. Is this what we would expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have estimated all the parameters, lets look how good the fit is to the training data. We will look at the mean squared error (MSE) to assess the goodness of fit.\n",
    "\n",
    "The **Mean Squared Error** is defined as:\n",
    "\n",
    "$$MSE~=~\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the metrics module from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (train)\n",
      "Linear: 0.0114570613511\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for training data\n",
    "fit_lm = lm.predict(X_train)\n",
    "\n",
    "# Print MSE for models\n",
    "print('MSE (train)')\n",
    "print('Linear:', metrics.mean_squared_error(y_train, fit_lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model can now be used to predict future stock returns. We use the predict() method on our model instance. Note that now we input the testing data => only the features since our model is already trained and now needs to predict the returns (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we test the accuracy of our predictions. To do this we compare our predictions with the labels of the testing dataset. Let's look at a graph of our predicted results vs. actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2ad79d8e518>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAFNCAYAAACuQMxrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nha1NUVUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ad79ce1b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure and axes\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Plot on axes\n",
    "ax.set_title('Actual vs Predicted')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlim(0, 0.4)\n",
    "ax.set_ylim(0, 0.4)\n",
    "ax.scatter(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at some statistical measures to test our output. In this case we use MSE. A low MSE means that our model generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.024466891723910568\n"
     ]
    }
   ],
   "source": [
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages & Disadvantages of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "\n",
    "* Very simple method and easy to understand \n",
    "* Able to determine the relative influence of one or more independent variables (features) to the dependent variable (labels)\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "* Only valid if there exists a linear relationship between dependent (labels) and independent (features) variables\n",
    "* Sensitive to outliers (i.e. outliers will impact estimated coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's the end of this tutorial. We covered what a MLR model is, how to build it and how make future predictions using the Scikit Learn library in Python. In the next tutorial we will look at a technique to improve the MLR model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
